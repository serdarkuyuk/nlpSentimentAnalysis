{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package             Version\r\n",
      "------------------- ---------\r\n",
      "altair              4.1.0\r\n",
      "appnope             0.1.2\r\n",
      "argon2-cffi         20.1.0\r\n",
      "astor               0.8.1\r\n",
      "async-generator     1.10\r\n",
      "attrs               20.3.0\r\n",
      "backcall            0.2.0\r\n",
      "base58              2.1.0\r\n",
      "bleach              3.3.0\r\n",
      "blinker             1.4\r\n",
      "blis                0.7.4\r\n",
      "cachetools          4.2.1\r\n",
      "catalogue           2.0.1\r\n",
      "certifi             2020.12.5\r\n",
      "cffi                1.14.4\r\n",
      "chardet             4.0.0\r\n",
      "click               7.1.2\r\n",
      "cymem               2.0.5\r\n",
      "decorator           4.4.2\r\n",
      "defusedxml          0.6.0\r\n",
      "docopt              0.6.2\r\n",
      "en-core-web-sm      3.0.0\r\n",
      "entrypoints         0.3\r\n",
      "gitdb               4.0.5\r\n",
      "GitPython           3.1.12\r\n",
      "idna                2.10\r\n",
      "ipykernel           5.4.3\r\n",
      "ipython             7.20.0\r\n",
      "ipython-genutils    0.2.0\r\n",
      "ipywidgets          7.6.3\r\n",
      "jedi                0.18.0\r\n",
      "Jinja2              2.11.3\r\n",
      "joblib              1.0.0\r\n",
      "jsonschema          3.2.0\r\n",
      "jupyter             1.0.0\r\n",
      "jupyter-client      6.1.11\r\n",
      "jupyter-console     6.2.0\r\n",
      "jupyter-core        4.7.1\r\n",
      "jupyterlab-pygments 0.1.2\r\n",
      "jupyterlab-widgets  1.0.0\r\n",
      "MarkupSafe          1.1.1\r\n",
      "mistune             0.8.4\r\n",
      "murmurhash          1.0.5\r\n",
      "nbclient            0.5.1\r\n",
      "nbconvert           6.0.7\r\n",
      "nbformat            5.1.2\r\n",
      "nest-asyncio        1.5.1\r\n",
      "notebook            6.2.0\r\n",
      "numpy               1.20.1\r\n",
      "packaging           20.9\r\n",
      "pandas              1.2.1\r\n",
      "pandocfilters       1.4.3\r\n",
      "parso               0.8.1\r\n",
      "pathy               0.3.5\r\n",
      "pexpect             4.8.0\r\n",
      "pickleshare         0.7.5\r\n",
      "Pillow              8.1.0\r\n",
      "pip                 20.2.3\r\n",
      "pipreqs             0.4.10\r\n",
      "preshed             3.0.5\r\n",
      "prometheus-client   0.9.0\r\n",
      "prompt-toolkit      3.0.14\r\n",
      "protobuf            3.14.0\r\n",
      "ptyprocess          0.7.0\r\n",
      "pycparser           2.20\r\n",
      "pydantic            1.7.3\r\n",
      "pydeck              0.6.0\r\n",
      "Pygments            2.7.4\r\n",
      "pyparsing           2.4.7\r\n",
      "pyrsistent          0.17.3\r\n",
      "python-dateutil     2.8.1\r\n",
      "pytz                2021.1\r\n",
      "pyzmq               22.0.2\r\n",
      "qtconsole           5.0.2\r\n",
      "QtPy                1.9.0\r\n",
      "requests            2.25.1\r\n",
      "scikit-learn        0.24.1\r\n",
      "scipy               1.6.0\r\n",
      "Send2Trash          1.5.0\r\n",
      "setuptools          49.2.1\r\n",
      "six                 1.15.0\r\n",
      "smart-open          3.0.0\r\n",
      "smmap               3.0.5\r\n",
      "spacy               3.0.1\r\n",
      "spacy-legacy        3.0.1\r\n",
      "spacy-lookups-data  1.0.0\r\n",
      "srsly               2.4.0\r\n",
      "streamlit           0.76.0\r\n",
      "terminado           0.9.2\r\n",
      "testpath            0.4.4\r\n",
      "thinc               8.0.1\r\n",
      "threadpoolctl       2.1.0\r\n",
      "toml                0.10.2\r\n",
      "toolz               0.11.1\r\n",
      "tornado             6.1\r\n",
      "tqdm                4.56.0\r\n",
      "traitlets           5.0.5\r\n",
      "typer               0.3.2\r\n",
      "tzlocal             2.1\r\n",
      "urllib3             1.26.3\r\n",
      "validators          0.18.2\r\n",
      "wasabi              0.8.2\r\n",
      "wcwidth             0.2.5\r\n",
      "webencodings        0.5.1\r\n",
      "widgetsnbextension  3.5.1\r\n",
      "yarg                0.1.9\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/Users/serdar/Documents/udel/python/nlpSentiment/nlpSentimentAnalysis/sentiment/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Apple is a great company. However, I am unaware of it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "be\n",
      "a\n",
      "great\n",
      "company\n",
      ".\n",
      "however\n",
      ",\n",
      "I\n",
      "be\n",
      "unaware\n",
      "of\n",
      "it\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is a great company. However, I am unaware of it.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I learned that if an electric slicer is used t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But they don't clean the chiles?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0                           Wow... Loved this place.        1.0\n",
       "1  I learned that if an electric slicer is used t...        NaN\n",
       "2                   But they don't clean the chiles?        NaN\n",
       "3                                 Crust is not good.        0.0\n",
       "4          Not tasty and the texture was just nasty.        0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_yelp = pd.read_csv('database/yelp.txt', sep='\\t', header = None)\n",
    "columns_name = ['Review', 'Sentiment']\n",
    "data_yelp.columns = columns_name\n",
    "data_yelp.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_amazon = pd.read_csv('database/amazon.txt', sep='\\t', header = None, error_bad_lines=False)\n",
    "columns_name = ['Review', 'Sentiment']\n",
    "data_amazon.columns = columns_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When I got this item it was larger than I thou...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I looked for one that specifically said DCU-6...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  So there is no way for me to plug it in here i...        0.0\n",
       "1                        Good case, Excellent value.        1.0\n",
       "2                             Great for the jawbone.        1.0\n",
       "3  When I got this item it was larger than I thou...        NaN\n",
       "4  (I looked for one that specifically said DCU-6...        NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_imdb = pd.read_csv('database/imdb.txt', sep='\\t', header = None, error_bad_lines=False)\n",
    "columns_name = ['Review', 'Sentiment']\n",
    "data_imdb.columns = columns_name\n",
    "data_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3729, 2), (14606, 2), (748, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_yelp.shape, data_amazon.shape, data_imdb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "punct = string.punctuation\n",
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seemed', 'first', 'mine', \"'ll\", 'whence', 'what', 'per', 'whatever', 'not', '’d', 'to', 'someone', 'these', 'then', 'will', 'nobody', 'rather', 'but', 'so', \"'d\", 'except', 'somehow', 'amount', 'nowhere', 'out', 'too', 'everything', 'even', 'nine', 'if', 'alone', 'thus', 'of', 'else', 'back', 'be', 'into', 'say', 'herein', 'however', 'serious', 'few', 'who', 'also', 'six', '‘d', 'hence', 'she', 'at', '’m', 'doing', 'under', 'either', 'do', 'three', 'much', 'us', 'beside', 'both', 'all', 'thereupon', 'why', 'must', 'thru', 'off', 'whereafter', 'see', 'therefore', 'whereupon', '’re', 'and', 'nevertheless', 'whither', 'below', 'please', 'really', 'it', 'mostly', 'noone', 'each', 'within', 'cannot', 'former', 'almost', 're', 'unless', 'after', 'have', 'made', 'empty', 'with', 'top', 'during', '‘m', 'though', '’ve', 'everywhere', 'down', 'anyone', 'part', 'i', 'whereas', 'sixty', 'otherwise', 'them', 'eight', 'somewhere', 'move', 'give', 'take', 'does', 'once', 'in', 'hereupon', 'seeming', 'get', 'further', 'becomes', 'another', 'among', 'together', 'meanwhile', 'than', 'several', 'how', 'before', 'whereby', 'others', 'well', 'hereby', 'namely', 'call', 'yourself', 'because', 'myself', 'itself', 'are', 'about', 'had', 'her', 'again', 'bottom', '‘s', 'eleven', \"'m\", \"'s\", 'as', 'was', 'seems', 'our', 'herself', 'toward', 'make', 'across', 'always', 'should', 'me', 'hereafter', 'show', 'has', 'go', 'least', 'same', 'for', 'more', 'thereby', 'hundred', 'nor', 'since', 'keep', 'anyhow', 'there', 'still', \"'ve\", 'while', 'put', 'whether', 'its', 'seem', 'whom', 'five', 'afterwards', 'using', 'thereafter', 'thence', 'they', 'on', 'am', 'onto', 'ours', 'over', 'without', 'full', 'name', 'behind', 'an', 'third', 'formerly', 'yours', 'via', 'due', 'neither', 'forty', 'twelve', 'hers', 'being', 'ever', 'two', 'becoming', 'would', 'less', 'been', 'elsewhere', 'used', 'he', 'front', '‘ll', 'one', 'moreover', 'some', 'himself', 'anywhere', 'him', '‘ve', 'a', 'side', 'towards', '‘re', 'no', 'although', 'latterly', 'or', 'anyway', 'very', 'just', 'perhaps', 'fifty', 'ca', 'own', 'any', 'often', 'enough', 'therein', 'became', 'fifteen', 'themselves', 'yourselves', 'various', 'may', 'every', 'up', 'whenever', 'none', 'such', 'until', 'yet', '’ll', 'did', 'his', 'this', 'many', 'four', 'next', \"n't\", 'sometimes', 'your', 'by', 'upon', 'other', 'regarding', 'above', 'now', 'wherever', 'already', 'nothing', 'whoever', '’s', 'might', 'along', 'besides', 'when', 'quite', 'something', 'wherein', 'last', 'whose', 'only', 'beyond', 'done', 'can', 'throughout', 'here', \"'re\", 'the', 'most', 'where', 'those', 'never', 'whole', 'my', 'twenty', 'between', 'from', 'sometime', 'is', 'n‘t', 'that', 'everyone', 'their', 'through', 'become', 'we', 'could', 'n’t', 'amongst', 'indeed', 'ourselves', 'against', 'were', 'anything', 'beforehand', 'around', 'which', 'ten', 'latter', 'you']\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stopwords = list(STOP_WORDS)\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class customNlp:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def text_data_cleaning(self,sentence):\n",
    "        doc = nlp(sentence)\n",
    "\n",
    "        tokens = []\n",
    "        for token in doc:\n",
    "            if token.lemma_ != \"-PRON-\":\n",
    "                temp = token.lemma_.lower().strip()\n",
    "            else:\n",
    "                temp = token.lower_\n",
    "            tokens.append(temp)\n",
    "\n",
    "        cleaned_tokens = []\n",
    "        for token in tokens:\n",
    "            if token not in stopwords and token not in punct:\n",
    "                cleaned_tokens.append(token)\n",
    "        return cleaned_tokens\n",
    "\n",
    "#myclass = customNlp()\n",
    "mysentence = customNlp().text_data_cleaning(\"Hello how are you. I love my girl\")\n",
    "print(mysentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_library.utils import customNlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'love', 'girl']\n"
     ]
    }
   ],
   "source": [
    "mysentence = customNlp().text_data_cleaning(\"Hello how are you. I love my girl\")\n",
    "print(mysentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19083, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_yelp.append([data_amazon, data_imdb], ignore_index=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1386\n",
       "0.0    1362\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review           0\n",
       "Sentiment    16335\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.0\n",
       "1        NaN\n",
       "2        NaN\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "19078    0.0\n",
       "19079    0.0\n",
       "19080    0.0\n",
       "19081    0.0\n",
       "19082    0.0\n",
       "Name: Sentiment, Length: 19083, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataready = data[data['Sentiment'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       0\n",
       "Sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataready.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer = customNlp().text_data_cleaning)\n",
    "classifier = LinearSVC(penalty='l2',C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataready['Review']\n",
    "y = dataready['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2198,), (550,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(tokenizer=<bound method customNlp.text_data_cleaning of <build_library.utils.customNlp object at 0x13347af40>>)),\n",
       "                ('clf', LinearSVC(C=1))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.81      0.80       285\n",
      "         1.0       0.79      0.75      0.77       265\n",
      "\n",
      "    accuracy                           0.79       550\n",
      "   macro avg       0.79      0.78      0.78       550\n",
      "weighted avg       0.79      0.79      0.79       550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[232,  53],\n",
       "       [ 65, 200]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(['Wow, this is amazing lesson'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(['Wow, this sucks'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(['Loved it. Amazing'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([customNlp,clf], open(\"pipeline.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('pipeline.pickle', 'rb')\n",
    "\n",
    "# dump information to that file\n",
    "mytest = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'build_library.utils.customNlp'>, Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(tokenizer=<bound method customNlp.text_data_cleaning of <build_library.utils.customNlp object at 0x134916a90>>)),\n",
      "                ('clf', LinearSVC(C=1))])]\n"
     ]
    }
   ],
   "source": [
    "print(mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'love', 'girl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytest[0]().text_data_cleaning(\"Hello how are you. I love my girl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
